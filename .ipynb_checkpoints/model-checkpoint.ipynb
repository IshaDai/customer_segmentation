{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5iwfK-0WjrPJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, train_test_split\n",
    "from sklearn import neighbors, linear_model, svm, tree, ensemble\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s0FaaGpEj352"
   },
   "outputs": [],
   "source": [
    "class Model_Fit(object):\n",
    "    def __init__(self, clf, params = None):\n",
    "        if params:\n",
    "            self.clf = clf(**params)\n",
    "        else:\n",
    "            self.clf = clf\n",
    "            \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "            \n",
    "    def predit(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def grid_search(self, parameters, Kfold):\n",
    "        self.grid = GridSearchCV(estimator = self.clf, param_grid = parameters, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1, cv = Kfold)\n",
    "\n",
    "    def grid_fit(self, x_train, y_train):\n",
    "        self.grid.fit(x_train, y_train)\n",
    "        \n",
    "    def grid_predict(self, x_train, y_train, x_test, y_test):\n",
    "        self.best_model = self.grid.best_estimator_\n",
    "        self.predictions = self.best_model.predict(x_test) # Use the best estimator from GridSearchCV to make predictions\n",
    "        self.y_test_pred = self.best_model.predict(x_test)\n",
    "\n",
    "        train_score = self.best_model.score(x_train, y_train)\n",
    "        test_score = self.best_model.score(x_test, y_test)\n",
    "\n",
    "        print(\"Accuracy score of training dataset: {:.2f} % \".format(100*train_score))\n",
    "        print(\"Accuracy score of testing dataset: {:.2f} % \".format(100*test_score))\n",
    "        print(\"R^2:\", metrics.r2_score(y_test, self.predictions))\n",
    "        print(\"MSE:\", metrics.mean_squared_error(y_test, self.predictions))\n",
    "        print(\"MAE:\", metrics.mean_absolute_error(y_test, self.predictions))\n",
    "        print(\"MAPE:\", metrics.mean_absolute_percentage_error(y_test, self.predictions))\n",
    "\n",
    "        return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-TTfIEhyvmgN"
   },
   "outputs": [],
   "source": [
    "# model algorithms \n",
    "def lgb_model(train_X, train_Y, test_X, test_Y, LGB, k):\n",
    "    print('Lightgbm:')\n",
    "    LGB.grid_search(parameters = [{'learning_rate': [0.05, 0.5, 1], 'max_depth': [-1, -2], 'reg_alpha': [0.1, 1], 'reg_lambda': [0.1, 1], 'n_estimators': [80, 100, 200]}], Kfold = k)\n",
    "    LGB.grid_fit(train_X, train_Y)\n",
    "    train_score, test_score = LGB.grid_predict(train_X, train_Y, test_X, test_Y) \n",
    "\n",
    "    return train_score, test_score\n",
    "    \n",
    "def xgb_model(train_X, train_Y, test_X, test_Y, XGB, k):\n",
    "    print('XGB:')\n",
    "    XGB.grid_search(parameters = {'objective': ['reg:squarederror'], 'learning_rate': [0.05, 0.5, 1], 'max_depth': [3,4,5], 'reg_alpha': [0.1, 1], 'reg_lambda': [0.1, 1]} , Kfold = k)\n",
    "    XGB.grid_fit(train_X, train_Y)\n",
    "    train_score, test_score = XGB.grid_predict(train_X, train_Y, test_X, test_Y) \n",
    "\n",
    "    return train_score, test_score\n",
    "\n",
    "def rf_model(train_X, train_Y, test_X, test_Y, RF, k):\n",
    "    print('RF:')\n",
    "    param_grid = {'criterion' : ['mse', 'friedman_mse'], 'n_estimators' : [80, 100, 200], 'max_depth': [3,4,5], 'max_features' :['sqrt', 'log2']}\n",
    "    RF.grid_search(parameters = param_grid, Kfold = k)\n",
    "    RF.grid_fit(train_X, train_Y)\n",
    "    train_score, test_score = RF.grid_predict(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "    return train_score, test_score\n",
    "\n",
    "def knn_model(train_X, train_Y, test_X, test_Y, KNN, k):\n",
    "    print('KNN:')\n",
    "    KNN.grid_search(parameters = [{'n_neighbors': np.arange(1,50,1), 'leaf_size': [6,9,12,15]}], Kfold = k)\n",
    "    KNN.grid_fit(train_X, train_Y)\n",
    "    train_score, test_score = KNN.grid_predict(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "    return train_score, test_score"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMiyT8Rr55RBWUbMTOo1Jl6",
   "mount_file_id": "1_1RnUq-JKyp97sYOuJwyHqQ2ObYIucTt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
